# Парсер страниц сайта с пагинацией.

## 1. Описание работы парсера.

Парсер извлекает текстовую информацию из кода набора страниц web-сайта с пагинацией для дальнейшей аналитической обработки. Для этого используются библиотеки
Python: bs4, requests, pandas.

На первом этапе через цикл программа делает запросы к страницам сайта, извлекает их HTML-код.
Что бы избежать большого числа запросов при написании и отладки парсера, а так-же - сохранить спарсимые
страницы в том виде, в котором они были на момент начала работ, полученный HTML-код в этом же цикле записывается в текстовые файлы.
Таким образом, при работе над парсером,
запросы к страницам уже не выполняются, а используются полученные файлы с их исходным кодом.

Так как текстовая информация извлекается для аналитической обработки - представим её в виде DataFrame библиотеки pandas, выполним простейшую предобработку
данных - уберём из полученных текстовых значений ненужные символы, приведём колонки таблицы к нужным типам. После чего сохраним полученную таблицу в exel - для её визуального представления,
и в csv - для дальнейшей аналитической обработки.

В этом примере мы спарсили интернет-магазин одежды - 7 страниц с пагинацией и получили таблицу со списком продаваемой одежды и ценами на неё.
Данные в таблице приведены к нужным типам и готовы к дальнейшей статистической обработки.  

## 2. План работы.

### [Часть 1:](unit_1.ipynb)

- подключение библиотеки requests;
- через цикл:
	- извлечение HTML-кода спарсимуемых страниц;
	- его сохранение в текстовых файлах.

### [Часть 2:](unit_2.ipynb)

- подключение библиотек bs4, pandas;
- подбор тегов с интересующей информацией;
- через цикл:
	- загрузка кода из полученных в 1-ой части файлов;
	- получение BeautifulSoup для парсинга;
	- получение текстового содержимого из интересующих тегов.
	- обработка полученных текстовых значений - в данном случае из значения цены убираем знак доллара и приводим к типу чисел с плавающей точкой. Из названий товара убираем пробелы перед строкой и после неё;
	- добавление полученных значений в список.
- конвертация полученного списка в DataFrame;
- запись полученной таблицы в exel и csv файлы.