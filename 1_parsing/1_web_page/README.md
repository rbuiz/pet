# Парсер страницы сайта.
## 1. Описание работы парсера.
Парсер извлекает текстовую информацию из кода страницы web-сайта для дальнейшей аналитической обработки. Для этого используются библиотеки
Python: bs4, requests, pandas.

Программа делает запрос к странице, получает её код. Что бы избежать большого числа запросов при написании и отладки кода, а так-же - сохранить спарсимую
страницу в том виде, в котором она была на момент начала работ, HTML-код записывается в текстовый файл. Далее, при написании и отладки кода самого парсера,
запросы к странице уже не делаем, а работаем с файлом с её HTML-кодом, который сохранён на локальном диске.

Так как текстовая информация извлекается для аналитической обработки - представим её в виде DataFrame библиотеки pandas, выполним простейшую предобработку
данных - заполним пропуски, приведём колонки таблицы к нужным типам. После чего сохраним полученную таблицу в exel - для её визуального представления,
и в csv - для дальнейшей аналитической обработки.

В этом примере получены сведения об интересных книгах определённой тематики - название книги, её авторы, число дочитываний, отказы, число цитирований и
коментариев и т.д. - всего по каждой книге 13 позиций.
## 2. План работы.
### [Часть 1](1_unit_1.ipynb):
- подключение библиотеки requests;
- извлечение HTML-кода спарсимуемой страницы;
- его сохранение в текстовом файле на локальном диске.
2. Часть 2:
- подключение библиотек bs4, pandas;
- загрузка в переменную HTML-кода из файла на локальном диске и получение BeautifulSoup для парсинга;
- подбор тегов с нужной информацией в коде страницы;
- парсинг - получение текстовых данных и их запись в таблицу;
- предобработка данных в полученном датафрейме;
- запись полученной таблицы в exel и csv файлы на локальном диске.